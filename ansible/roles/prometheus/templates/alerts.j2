groups:
- name: k8s.rules
  rules:
  - expr: |
      sum(rate(container_cpu_usage_seconds_total{job="kubelet", image!="", container_name!=""}[5m])) by (kubernetes_namespace)
    record: namespace:container_cpu_usage_seconds_total:sum_rate
  - expr: |
      sum by (kubernetes_namespace, pod_name, container_name) (
        rate(container_cpu_usage_seconds_total{job="kubelet", image!="", container_name!=""}[5m])
      )
    record: namespace_pod_name_container_name:container_cpu_usage_seconds_total:sum_rate
  - expr: |
      sum(container_memory_usage_bytes{job="kubelet", image!="", container_name!=""}) by (kubernetes_namespace)
    record: namespace:container_memory_usage_bytes:sum
  - expr: |
      sum by (kubernetes_namespace, label_name) (
         sum(rate(container_cpu_usage_seconds_total{job="kubelet", image!="", container_name!=""}[5m])) by (kubernetes_namespace, pod_name)
       * on (kubernetes_namespace, pod_name) group_left(label_name)
         label_replace(kube_pod_labels{component="kube-state-metrics"}, "pod_name", "$1", "pod", "(.*)")
      )
    record: namespace_name:container_cpu_usage_seconds_total:sum_rate
  - expr: |
      sum by (kubernetes_namespace, label_name) (
        sum(container_memory_usage_bytes{job="kubelet",image!="", container_name!=""}) by (pod_name, kubernetes_namespace)
      * on (kubernetes_namespace, pod_name) group_left(label_name)
        label_replace(kube_pod_labels{component="kube-state-metrics"}, "pod_name", "$1", "pod", "(.*)")
      )
    record: namespace_name:container_memory_usage_bytes:sum
  - expr: |
      sum by (kubernetes_namespace, label_name) (
        sum(kube_pod_container_resource_requests_memory_bytes{component="kube-state-metrics"}) by (kubernetes_namespace, pod)
      * on (kubernetes_namespace, pod) group_left(label_name)
        label_replace(kube_pod_labels{component="kube-state-metrics"}, "pod_name", "$1", "pod", "(.*)")
      )
    record: namespace_name:kube_pod_container_resource_requests_memory_bytes:sum
  - expr: |
      sum by (kubernetes_namespace, label_name) (
        sum(kube_pod_container_resource_requests_cpu_cores{component="kube-state-metrics"} and on(pod) kube_pod_status_scheduled{condition="true"}) by (kubernetes_namespace, pod)
      * on (kubernetes_namespace, pod) group_left(label_name)
        label_replace(kube_pod_labels{component="kube-state-metrics"}, "pod_name", "$1", "pod", "(.*)")
      )
    record: namespace_name:kube_pod_container_resource_requests_cpu_cores:sum
- name: kube-scheduler.rules
  rules:
  - expr: |
      histogram_quantile(0.99, sum(rate(scheduler_e2e_scheduling_latency_microseconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod)) / 1e+06
    labels:
      quantile: "0.99"
    record: cluster_quantile:scheduler_e2e_scheduling_latency:histogram_quantile
  - expr: |
      histogram_quantile(0.99, sum(rate(scheduler_scheduling_algorithm_latency_microseconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod)) / 1e+06
    labels:
      quantile: "0.99"
    record: cluster_quantile:scheduler_scheduling_algorithm_latency:histogram_quantile
  - expr: |
      histogram_quantile(0.99, sum(rate(scheduler_binding_latency_microseconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod)) / 1e+06
    labels:
      quantile: "0.99"
    record: cluster_quantile:scheduler_binding_latency:histogram_quantile
  - expr: |
      histogram_quantile(0.9, sum(rate(scheduler_e2e_scheduling_latency_microseconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod)) / 1e+06
    labels:
      quantile: "0.9"
    record: cluster_quantile:scheduler_e2e_scheduling_latency:histogram_quantile
  - expr: |
      histogram_quantile(0.9, sum(rate(scheduler_scheduling_algorithm_latency_microseconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod)) / 1e+06
    labels:
      quantile: "0.9"
    record: cluster_quantile:scheduler_scheduling_algorithm_latency:histogram_quantile
  - expr: |
      histogram_quantile(0.9, sum(rate(scheduler_binding_latency_microseconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod)) / 1e+06
    labels:
      quantile: "0.9"
    record: cluster_quantile:scheduler_binding_latency:histogram_quantile
  - expr: |
      histogram_quantile(0.5, sum(rate(scheduler_e2e_scheduling_latency_microseconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod)) / 1e+06
    labels:
      quantile: "0.5"
    record: cluster_quantile:scheduler_e2e_scheduling_latency:histogram_quantile
  - expr: |
      histogram_quantile(0.5, sum(rate(scheduler_scheduling_algorithm_latency_microseconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod)) / 1e+06
    labels:
      quantile: "0.5"
    record: cluster_quantile:scheduler_scheduling_algorithm_latency:histogram_quantile
  - expr: |
      histogram_quantile(0.5, sum(rate(scheduler_binding_latency_microseconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod)) / 1e+06
    labels:
      quantile: "0.5"
    record: cluster_quantile:scheduler_binding_latency:histogram_quantile
- name: kube-apiserver.rules
  rules:
  - expr: |
      histogram_quantile(0.99, sum(rate(apiserver_request_latencies_bucket{job="kubernetes-apiserver"}[5m])) without(instance, pod)) / 1e+06
    labels:
      quantile: "0.99"
    record: cluster_quantile:apiserver_request_latencies:histogram_quantile
  - expr: |
      histogram_quantile(0.9, sum(rate(apiserver_request_latencies_bucket{job="kubernetes-apiserver"}[5m])) without(instance, pod)) / 1e+06
    labels:
      quantile: "0.9"
    record: cluster_quantile:apiserver_request_latencies:histogram_quantile
  - expr: |
      histogram_quantile(0.5, sum(rate(apiserver_request_latencies_bucket{job="kubernetes-apiserver"}[5m])) without(instance, pod)) / 1e+06
    labels:
      quantile: "0.5"
    record: cluster_quantile:apiserver_request_latencies:histogram_quantile
- name: node.rules
  rules:
  - expr: sum(min(kube_pod_info) by (node))
    record: ':kube_pod_info_node_count:'
  - expr: |
      max(label_replace(kube_pod_info{component="kube-state-metrics"}, "pod", "$1", "pod", "(.*)")) by (node, kubernetes_namespace, pod)
    record: 'node_namespace_pod:kube_pod_info:'
  - expr: |
      count by (node) (sum by (node, cpu) (
        node_cpu{job="kubernetes-pods"}
      * on (kubernetes_namespace, pod) group_left(node)
        node_namespace_pod:kube_pod_info:
      ))
    record: node:node_num_cpu:sum
  - expr: |
      1 - avg(rate(node_cpu{job="kubernetes-pods",mode="idle"}[1m]))
    record: :node_cpu_utilisation:avg1m
  - expr: |
      1 - avg by (node) (
        rate(node_cpu{job="kubernetes-pods",mode="idle"}[1m])
      * on (kubernetes_namespace, pod) group_left(node)
        node_namespace_pod:kube_pod_info:)
    record: node:node_cpu_utilisation:avg1m
  - expr: |
      sum(node_load1{job="kubernetes-pods"})
      /
      sum(node:node_num_cpu:sum)
    record: ':node_cpu_saturation_load1:'
  - expr: |
      sum by (node) (
        node_load1{job="kubernetes-pods"}
      * on (kubernetes_namespace, pod) group_left(node)
        node_namespace_pod:kube_pod_info:
      )
      /
      node:node_num_cpu:sum
    record: 'node:node_cpu_saturation_load1:'
  - expr: |
      1 -
      sum(node_memory_MemFree{job="kubernetes-pods"} + node_memory_Cached{job="kubernetes-pods"} + node_memory_Buffers{job="kubernetes-pods"})
      /
      sum(node_memory_MemTotal{job="kubernetes-pods"})
    record: ':node_memory_utilisation:'
  - expr: |
      sum(node_memory_MemFree{job="kubernetes-pods"} + node_memory_Cached{job="kubernetes-pods"} + node_memory_Buffers{job="kubernetes-pods"})
    record: :node_memory_MemFreeCachedBuffers:sum
  - expr: |
      sum(node_memory_MemTotal{job="kubernetes-pods"})
    record: :node_memory_MemTotal:sum
  - expr: |
      sum by (node) (
        (node_memory_MemFree{job="kubernetes-pods"} + node_memory_Cached{job="kubernetes-pods"} + node_memory_Buffers{job="kubernetes-pods"})
        * on (kubernetes_namespace, pod) group_left(node)
          node_namespace_pod:kube_pod_info:
      )
    record: node:node_memory_bytes_available:sum
  - expr: |
      sum by (node) (
        node_memory_MemTotal{job="kubernetes-pods"}
        * on (kubernetes_namespace, pod) group_left(node)
          node_namespace_pod:kube_pod_info:
      )
    record: node:node_memory_bytes_total:sum
  - expr: |
      (node:node_memory_bytes_total:sum - node:node_memory_bytes_available:sum)
      /
      scalar(sum(node:node_memory_bytes_total:sum))
    record: node:node_memory_utilisation:ratio
  - expr: |
      1e3 * sum(
        (rate(node_vmstat_pgpgin{job="kubernetes-pods"}[1m])
       + rate(node_vmstat_pgpgout{job="kubernetes-pods"}[1m]))
      )
    record: :node_memory_swap_io_bytes:sum_rate
  - expr: |
      1 -
      sum by (node) (
        (node_memory_MemFree{job="kubernetes-pods"} + node_memory_Cached{job="kubernetes-pods"} + node_memory_Buffers{job="kubernetes-pods"})
      * on (kubernetes_namespace, pod) group_left(node)
        node_namespace_pod:kube_pod_info:
      )
      /
      sum by (node) (
        node_memory_MemTotal{job="kubernetes-pods"}
      * on (kubernetes_namespace, pod) group_left(node)
        node_namespace_pod:kube_pod_info:
      )
    record: 'node:node_memory_utilisation:'
  - expr: |
      1 - (node:node_memory_bytes_available:sum / node:node_memory_bytes_total:sum)
    record: 'node:node_memory_utilisation_2:'
  - expr: |
      1e3 * sum by (node) (
        (rate(node_vmstat_pgpgin{job="kubernetes-pods"}[1m])
       + rate(node_vmstat_pgpgout{job="kubernetes-pods"}[1m]))
       * on (kubernetes_namespace, pod) group_left(node)
         node_namespace_pod:kube_pod_info:
      )
    record: node:node_memory_swap_io_bytes:sum_rate
  - expr: |
      avg(irate(node_disk_io_time_ms{job="kubernetes-pods",device=~"(sd|xvd|nvme).+"}[1m]) / 1e3)
    record: :node_disk_utilisation:avg_irate
  - expr: |
      avg by (node) (
        irate(node_disk_io_time_ms{job="kubernetes-pods",device=~"(sd|xvd|nvme).+"}[1m]) / 1e3
      * on (kubernetes_namespace, pod) group_left(node)
        node_namespace_pod:kube_pod_info:
      )
    record: node:node_disk_utilisation:avg_irate
  - expr: |
      avg(irate(node_disk_io_time_weighted{job="kubernetes-pods",device=~"(sd|xvd|nvme).+"}[1m]) / 1e3)
    record: :node_disk_saturation:avg_irate
  - expr: |
      avg by (node) (
        irate(node_disk_io_time_weighted{job="kubernetes-pods",device=~"(sd|xvd|nvme).+"}[1m]) / 1e3
      * on (kubernetes_namespace, pod) group_left(node)
        node_namespace_pod:kube_pod_info:
      )
    record: node:node_disk_saturation:avg_irate
  - expr: |
      max by (kubernetes_namespace, pod, device) ((node_filesystem_size{fstype=~"ext[234]|btrfs|xfs|zfs"}
      - node_filesystem_avail{fstype=~"ext[234]|btrfs|xfs|zfs"})
      / node_filesystem_size{fstype=~"ext[234]|btrfs|xfs|zfs"})
    record: 'node:node_filesystem_usage:'
  - expr: |
      max by (kubernetes_namespace, pod, device) (node_filesystem_avail{fstype=~"ext[234]|btrfs|xfs|zfs"} / node_filesystem_size{fstype=~"ext[234]|btrfs|xfs|zfs"})
    record: 'node:node_filesystem_avail:'
  - expr: |
      sum(irate(node_network_receive_bytes{job="kubernetes-pods",device="eth0"}[1m])) +
      sum(irate(node_network_transmit_bytes{job="kubernetes-pods",device="eth0"}[1m]))
    record: :node_net_utilisation:sum_irate
  - expr: |
      sum by (node) (
        (irate(node_network_receive_bytes{job="kubernetes-pods",device="eth0"}[1m]) +
        irate(node_network_transmit_bytes{job="kubernetes-pods",device="eth0"}[1m]))
      * on (kubernetes_namespace, pod) group_left(node)
        node_namespace_pod:kube_pod_info:
      )
    record: node:node_net_utilisation:sum_irate
  - expr: |
      sum(irate(node_network_receive_drop{job="kubernetes-pods",device="eth0"}[1m])) +
      sum(irate(node_network_transmit_drop{job="kubernetes-pods",device="eth0"}[1m]))
    record: :node_net_saturation:sum_irate
  - expr: |
      sum by (node) (
        (irate(node_network_receive_drop{job="kubernetes-pods",device="eth0"}[1m]) +
        irate(node_network_transmit_drop{job="kubernetes-pods",device="eth0"}[1m]))
      * on (kubernetes_namespace, pod) group_left(node)
        node_namespace_pod:kube_pod_info:
      )
    record: node:node_net_saturation:sum_irate
- name: kube-prometheus-node-recording.rules
  rules:
  - expr: sum(rate(node_cpu{mode!="idle",mode!="iowait"}[3m])) BY (instance)
    record: instance:node_cpu:rate:sum
  - expr: sum((node_filesystem_size{mountpoint="/"} - node_filesystem_free{mountpoint="/"}))
      BY (instance)
    record: instance:node_filesystem_usage:sum
  - expr: sum(rate(node_network_receive_bytes[3m])) BY (instance)
    record: instance:node_network_receive_bytes:rate:sum
  - expr: sum(rate(node_network_transmit_bytes[3m])) BY (instance)
    record: instance:node_network_transmit_bytes:rate:sum
  - expr: sum(rate(node_cpu{mode!="idle",mode!="iowait"}[5m])) WITHOUT (cpu, mode)
      / ON(instance) GROUP_LEFT() count(sum(node_cpu) BY (instance, cpu)) BY (instance)
    record: instance:node_cpu:ratio
  - expr: sum(rate(node_cpu{mode!="idle",mode!="iowait"}[5m]))
    record: cluster:node_cpu:sum_rate5m
  - expr: cluster:node_cpu:rate5m / count(sum(node_cpu) BY (instance, cpu))
    record: cluster:node_cpu:ratio
- name: node_exporter-16-bcache
  rules:
  - expr: node_bcache_cache_read_races
    record: node_bcache_cache_read_races_total
- name: node_exporter-16-buddyinfo
  rules:
  - expr: node_buddyinfo_blocks
    record: node_buddyinfo_count
- name: node_exporter-16-stat
  rules:
  - expr: node_boot_time_seconds
    record: node_boot_time
  - expr: node_context_switches_total
    record: node_context_switches
  - expr: node_forks_total
    record: node_forks
  - expr: node_intr_total
    record: node_intr
- name: node_exporter-16-cpu
  rules:
  - expr: label_replace(node_cpu_seconds_total, "cpu", "$1", "cpu", "cpu(.+)")
    record: node_cpu
- name: node_exporter-16-diskstats
  rules:
  - expr: node_disk_read_bytes_total
    record: node_disk_bytes_read
  - expr: node_disk_written_bytes_total
    record: node_disk_bytes_written
  - expr: node_disk_io_time_seconds_total * 1000
    record: node_disk_io_time_ms
  - expr: node_disk_io_time_weighted_seconds_total
    record: node_disk_io_time_weighted
  - expr: node_disk_reads_completed_total
    record: node_disk_reads_completed
  - expr: node_disk_reads_merged_total
    record: node_disk_reads_merged
  - expr: node_disk_read_time_seconds_total * 1000
    record: node_disk_read_time_ms
  - expr: node_disk_writes_completed_total
    record: node_disk_writes_completed
  - expr: node_disk_writes_merged_total
    record: node_disk_writes_merged
  - expr: node_disk_write_time_seconds_total * 1000
    record: node_disk_write_time_ms
- name: node_exporter-16-filesystem
  rules:
  - expr: node_filesystem_free_bytes
    record: node_filesystem_free
  - expr: node_filesystem_avail_bytes
    record: node_filesystem_avail
  - expr: node_filesystem_size_bytes
    record: node_filesystem_size
- name: node_exporter-16-infiniband
  rules:
  - expr: node_infiniband_port_data_received_bytes_total
    record: node_infiniband_port_data_received_bytes
  - expr: node_infiniband_port_data_transmitted_bytes_total
    record: node_infiniband_port_data_transmitted_bytes
- name: node_exporter-16-interrupts
  rules:
  - expr: node_interrupts_total
    record: node_interrupts
- name: node_exporter-16-memory
  rules:
  - expr: node_memory_Active_bytes
    record: node_memory_Active
  - expr: node_memory_Active_anon_bytes
    record: node_memory_Active_anon
  - expr: node_memory_Active_file_bytes
    record: node_memory_Active_file
  - expr: node_memory_AnonHugePages_bytes
    record: node_memory_AnonHugePages
  - expr: node_memory_AnonPages_bytes
    record: node_memory_AnonPages
  - expr: node_memory_Bounce_bytes
    record: node_memory_Bounce
  - expr: node_memory_Buffers_bytes
    record: node_memory_Buffers
  - expr: node_memory_Cached_bytes
    record: node_memory_Cached
  - expr: node_memory_CommitLimit_bytes
    record: node_memory_CommitLimit
  - expr: node_memory_Committed_AS_bytes
    record: node_memory_Committed_AS
  - expr: node_memory_DirectMap2M_bytes
    record: node_memory_DirectMap2M
  - expr: node_memory_DirectMap4k_bytes
    record: node_memory_DirectMap4k
  - expr: node_memory_Dirty_bytes
    record: node_memory_Dirty
  - expr: node_memory_HardwareCorrupted_bytes
    record: node_memory_HardwareCorrupted
  - expr: node_memory_Hugepagesize_bytes
    record: node_memory_Hugepagesize
  - expr: node_memory_Inactive_bytes
    record: node_memory_Inactive
  - expr: node_memory_Inactive_anon_bytes
    record: node_memory_Inactive_anon
  - expr: node_memory_Inactive_file_bytes
    record: node_memory_Inactive_file
  - expr: node_memory_KernelStack_bytes
    record: node_memory_KernelStack
  - expr: node_memory_Mapped_bytes
    record: node_memory_Mapped
  - expr: node_memory_MemAvailable_bytes
    record: node_memory_MemAvailable
  - expr: node_memory_MemFree_bytes
    record: node_memory_MemFree
  - expr: node_memory_MemTotal_bytes
    record: node_memory_MemTotal
  - expr: node_memory_Mlocked_bytes
    record: node_memory_Mlocked
  - expr: node_memory_NFS_Unstable_bytes
    record: node_memory_NFS_Unstable
  - expr: node_memory_PageTables_bytes
    record: node_memory_PageTables
  - expr: node_memory_Shmem_bytes
    record: node_memory_Shmem
  - expr: node_memory_Slab_bytes
    record: node_memory_Slab
  - expr: node_memory_SReclaimable_bytes
    record: node_memory_SReclaimable
  - expr: node_memory_SUnreclaim_bytes
    record: node_memory_SUnreclaim
  - expr: node_memory_SwapCached_bytes
    record: node_memory_SwapCached
  - expr: node_memory_SwapFree_bytes
    record: node_memory_SwapFree
  - expr: node_memory_SwapTotal_bytes
    record: node_memory_SwapTotal
  - expr: node_memory_Unevictable_bytes
    record: node_memory_Unevictable
  - expr: node_memory_VmallocChunk_bytes
    record: node_memory_VmallocChunk
  - expr: node_memory_VmallocTotal_bytes
    record: node_memory_VmallocTotal
  - expr: node_memory_VmallocUsed_bytes
    record: node_memory_VmallocUsed
  - expr: node_memory_Writeback_bytes
    record: node_memory_Writeback
  - expr: node_memory_WritebackTmp_bytes
    record: node_memory_WritebackTmp
- name: node_exporter-16-network
  rules:
  - expr: node_network_receive_bytes_total
    record: node_network_receive_bytes
  - expr: node_network_receive_compressed_total
    record: node_network_receive_compressed
  - expr: node_network_receive_drop_total
    record: node_network_receive_drop
  - expr: node_network_receive_errs_total
    record: node_network_receive_errs
  - expr: node_network_receive_fifo_total
    record: node_network_receive_fifo
  - expr: node_network_receive_frame_total
    record: node_network_receive_frame
  - expr: node_network_receive_multicast_total
    record: node_network_receive_multicast
  - expr: node_network_receive_packets_total
    record: node_network_receive_packets
  - expr: node_network_transmit_bytes_total
    record: node_network_transmit_bytes
  - expr: node_network_transmit_compressed_total
    record: node_network_transmit_compressed
  - expr: node_network_transmit_drop_total
    record: node_network_transmit_drop
  - expr: node_network_transmit_errs_total
    record: node_network_transmit_errs
  - expr: node_network_transmit_fifo_total
    record: node_network_transmit_fifo
  - expr: node_network_transmit_frame_total
    record: node_network_transmit_frame
  - expr: node_network_transmit_multicast_total
    record: node_network_transmit_multicast
  - expr: node_network_transmit_packets_total
    record: node_network_transmit_packets
- name: node_exporter-16-nfs
  rules:
  - expr: node_nfs_connections_total
    record: node_nfs_net_connections
  - expr: node_nfs_packets_total
    record: node_nfs_net_reads
  - expr: label_replace(label_replace(node_nfs_requests_total, "proto", "$1", "version",
      "(.+)"), "method", "$1", "procedure", "(.+)")
    record: node_nfs_procedures
  - expr: node_nfs_rpc_authentication_refreshes_total
    record: node_nfs_rpc_authentication_refreshes
  - expr: node_nfs_rpcs_total
    record: node_nfs_rpc_operations
  - expr: node_nfs_rpc_retransmissions_total
    record: node_nfs_rpc_retransmissions
- name: node_exporter-16-textfile
  rules:
  - expr: node_textfile_mtime_seconds
    record: node_textfile_mtime
- name: kubernetes-absent
  rules:
  - alert: {{ cluster }} AlertmanagerDown
    annotations:
      message: Alertmanager has disappeared from Prometheus target discovery.
      runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-alertmanagerdown
    expr: |
      # absent(prometheus_notifications_alertmanagers_discovered{job="prometheus",instance="localhost:9090"} == 1)
      absent(up{app="prometheus",component="alertmanager"} == 1)
    for: 15m
    labels:
      severity: critical
  - alert: {{ cluster }} KubeAPIDown
    annotations:
      message: KubeAPI has disappeared from Prometheus target discovery.
      runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeapidown
    expr: |
      absent(up{job="kubernetes-apiservers"} == 1)
    for: 15m
    labels:
      severity: critical
  - alert: {{ cluster }} KubeletDown
    annotations:
      message: Kubelet has disappeared from Prometheus target discovery.
      runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeletdown
    expr: |
      absent(up{job="kubelet"} == 1)
    for: 15m
    labels:
      severity: critical
  - alert: {{ cluster }} KubeControllerManagerDown
    annotations:
      message: KubeControllerManager has disappeared from Prometheus target discovery.
      runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubecontrollermanagerdown
    expr: |
      absent(up{job="kube-controller-manager"} == 1)
    for: 15m
    labels:
      severity: critical
  - alert: {{ cluster }} KubeSchedulerDown
    annotations:
      message: KubeScheduler has disappeared from Prometheus target discovery.
      runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeschedulerdown
    expr: |
      absent(up{job="kube-scheduler"} == 1)
    for: 15m
    labels:
      severity: critical
  - alert: {{ cluster }} KubeStateMetricsDown
    annotations:
      message: KubeStateMetrics has disappeared from Prometheus target discovery.
      runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubestatemetricsdown
    expr: |
      absent(up{app="kube-state-metrics",job="kubernetes-service-endpoints"} == 1)
    for: 15m
    labels:
      severity: critical
  - alert: {{ cluster }} NodeExporterDown
    annotations:
      message: NodeExporter has disappeared from Prometheus target discovery.
      runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-nodeexporterdown
    expr: |
      absent(up{app="prometheus-node-exporter"} == 1)
    for: 15m
    labels:
      severity: critical
  - alert: {{ cluster }} PrometheusDown
    annotations:
      message: Prometheus has disappeared from Prometheus target discovery.
      runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-prometheusdown
    expr: |
      absent(up{app="prometheus",component="server"} == 1)
    for: 15m
    labels:
      severity: critical
- name: kubernetes-apps
  rules:
  - alert: {{ cluster }} KubeDaemonSetRolloutStuck
    annotations:
      message: {% raw %}Only {{ $value }}% of the desired Pods of DaemonSet {{ $labels.kubernetes_namespace
        }}/{{ $labels.daemonset }} are scheduled and ready.{% endraw %}

      runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubedaemonsetrolloutstuck
    expr: |
      kube_daemonset_status_number_ready{component="kube-state-metrics"}
        /
      kube_daemonset_status_desired_number_scheduled{component="kube-state-metrics"} * 100 < 100
    for: 15m
    labels:
      severity: critical
  - alert: {{ cluster }} KubeDaemonSetNotScheduled
    annotations:
      message: {% raw %}'{{ $value }} Pods of DaemonSet {{ $labels.kubernetes_namespace }}/{{
        $labels.daemonset }} are not scheduled.'{% endraw %}

      runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubedaemonsetnotscheduled
    expr: |
      kube_daemonset_status_desired_number_scheduled{component="kube-state-metrics"}
        -
      kube_daemonset_status_current_number_scheduled{component="kube-state-metrics"} > 0
    for: 10m
    labels:
      severity: warning
  - alert: {{ cluster }} KubeDaemonSetMisScheduled
    annotations:
      message: {% raw %}'{{ $value }} Pods of DaemonSet {{ $labels.kubernetes_namespace }}/{{
        $labels.daemonset }} are running where they are not supposed to run.'{% endraw %}

      runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubedaemonsetmisscheduled
    expr: |
      kube_daemonset_status_number_misscheduled{component="kube-state-metrics"} > 0
    for: 10m
    labels:
      severity: warning
  - alert: {{ cluster }} KubeCronJobRunning
    annotations:
      message: {% raw %}CronJob {{ $labels.kubernetes_namespace }}/{{ $labels.cronjob }}
        is taking more than 1h to complete.{% endraw %}

      runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubecronjobrunning
    expr: |
      time() - kube_cronjob_next_schedule_time{component="kube-state-metrics"} > 3600
    for: 1h
    labels:
      severity: warning
  - alert: {{ cluster }} KubeJobCompletion
    annotations:
      message: {% raw %}Job {{ $labels.kubernetes_namespace }}/{{ $labels.job }} is taking
        more than one hour to complete.{% endraw %}

      runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubejobcompletion
    expr: |
      kube_job_spec_completions{component="kube-state-metrics"} - kube_job_status_succeeded{component="kube-state-metrics"}  > 0
    for: 1h
    labels:
      severity: warning
  - alert: {{ cluster }} KubeJobFailed
    annotations:
      message: Job {% raw %}{{ $labels.kubernetes_namespace }}/{{ $labels.job }} failed to
        complete.{% endraw %}

      runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubejobfailed
    expr: |
      kube_job_status_failed{component="kube-state-metrics"}  > 0
    for: 1h
    labels:
      severity: warning
- name: kubernetes-resources
  rules:
  - alert: {{ cluster }} KubeCPUOvercommit
    annotations:
      message: Cluster has overcommitted CPU resource requests for Pods and cannot
        tolerate node failure.
      runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubecpuovercommit
    expr: |
      sum(namespace_name:kube_pod_container_resource_requests_cpu_cores:sum)
        /
      sum(node:node_num_cpu:sum)
        >
      (count(node:node_num_cpu:sum)-1) / count(node:node_num_cpu:sum)
    for: 5m
    labels:
      severity: warning
  - alert: {{ cluster }} KubeMemOvercommit
    annotations:
      message: Cluster has overcommitted memory resource requests for Pods and cannot
        tolerate node failure.
      runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubememovercommit
    expr: |
      sum(namespace_name:kube_pod_container_resource_requests_memory_bytes:sum)
        /
      sum(node_memory_MemTotal)
        >
      (count(node:node_num_cpu:sum)-1)
        /
      count(node:node_num_cpu:sum)
    for: 5m
    labels:
      severity: warning
  - alert: {{ cluster }} KubeCPUOvercommit
    annotations:
      message: Cluster has overcommitted CPU resource requests for Namespaces.
      runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubecpuovercommit
    expr: |
      sum(kube_resourcequota{component="kube-state-metrics", type="hard", resource="requests.cpu"})
        /
      sum(node:node_num_cpu:sum)
        > 1.5
    for: 5m
    labels:
      severity: warning
  - alert: {{ cluster }} KubeMemOvercommit
    annotations:
      message: Cluster has overcommitted memory resource requests for Namespaces.
      runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubememovercommit
    expr: |
      sum(kube_resourcequota{component="kube-state-metrics", type="hard", resource="requests.memory"})
        /
      sum(node_memory_MemTotal{job="kubernetes-pods"})
        > 1.5
    for: 5m
    labels:
      severity: warning
  - alert: {{ cluster }} KubeQuotaExceeded
    annotations:
      message: {% raw %}Namespace {{ $labels.kubernetes_namespace }} is using {{ printf "%0.0f"
        $value }}% of its {{ $labels.resource }} quota.{% endraw %}

      runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubequotaexceeded
    expr: |
      100 * kube_resourcequota{component="kube-state-metrics", type="used"}
        / ignoring(instance, job, type)
      (kube_resourcequota{component="kube-state-metrics", type="hard"} > 0)
        > 90
    for: 15m
    labels:
      severity: warning
- name: kubernetes-storage
  rules:
  - alert: {{ cluster }} KubePersistentVolumeUsageCritical
    annotations:
      message: {% raw %}The PersistentVolume claimed by {{ $labels.persistentvolumeclaim
        }} in Namespace {{ $labels.kubernetes_namespace }} is only {{ printf "%0.0f"
        $value }}% free.{% endraw %}

      runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubepersistentvolumeusagecritical
    expr: |
      100 * kubelet_volume_stats_available_bytes{job="kubelet"}
        /
      kubelet_volume_stats_capacity_bytes{job="kubelet"}
        < 3
    for: 1m
    labels:
      severity: critical
  - alert: {{ cluster }} KubePersistentVolumeFullInFourDays
    annotations:
      message: {% raw %}Based on recent sampling, the PersistentVolume claimed by {{ $labels.persistentvolumeclaim
        }} in Namespace {{ $labels.kubernetes_namespace }} is expected to fill up within
        four days. Currently {{ $value }} bytes are available.{% endraw %}

      runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubepersistentvolumefullinfourdays
    expr: |
      kubelet_volume_stats_available_bytes{job="kubelet"} and predict_linear(kubelet_volume_stats_available_bytes{job="kubelet"}[6h], 4 * 24 * 3600) < 0
    for: 5m
    labels:
      severity: critical
- name: kubernetes-system
  rules:
  - alert: {{ cluster }} KubeNodeNotReady
    annotations:
      message: {% raw %}'{{ $labels.node }} has been unready for more than an hour.'{% endraw %}

      runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubenodenotready
    expr: |
      kube_node_status_condition{component="kube-state-metrics",condition="Ready",status="true"} == 0
    for: 1h
    labels:
      severity: warning
  - alert: {{ cluster }} KubeVersionMismatch
    annotations:
      message: {% raw %}There are {{ $value }} different versions of Kubernetes components
        running.{% endraw %}

      runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeversionmismatch
    expr: |
      count(count(kubernetes_build_info{job!="kube-dns"}) by (gitVersion)) > 1
    for: 1h
    labels:
      severity: warning
  - alert: {{ cluster }} KubeClientErrors
    annotations:
      message: {% raw %}Kubernetes API server client '{{ $labels.job }}/{{ $labels.instance
        }}' is experiencing {{ printf "%0.0f" $value }}% errors.'{% endraw %}

      runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeclienterrors
    expr: |
      (sum(rate(rest_client_requests_total{code!~"2..|404"}[5m])) by (instance, job)
        /
      sum(rate(rest_client_requests_total[5m])) by (instance, job))
      * 100 > 1
    for: 15m
    labels:
      severity: warning
  - alert: {{ cluster }} KubeClientErrors
    annotations:
      message: {% raw %}Kubernetes API server client '{{ $labels.job }}/{{ $labels.instance
        }}' is experiencing {{ printf "%0.0f" $value }} errors / second.{% endraw %}

      runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeclienterrors
    expr: |
      sum(rate(ksm_scrape_error_total{component="kube-state-metrics"}[5m])) by (instance, job) > 0.1
    for: 15m
    labels:
      severity: warning
  - alert: {{ cluster }} KubeletTooManyPods
    annotations:
      message: {% raw %}Kubelet {{ $labels.instance }} is running {{ $value }}
        Pods, close to the limit of 110.{% endraw %}

      runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubelettoomanypods
    expr: |
      kubelet_running_pod_count{job="kubelet"} > 110 * 0.9
    for: 15m
    labels:
      severity: warning
  - alert: {{ cluster }} KubeAPILatencyHigh
    annotations:
      message: {% raw %}The API server has a 99th percentile latency of {{ $value }}
        seconds for {{ $labels.verb }} {{ $labels.resource }}.{% endraw %}

      runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeapilatencyhigh
    expr: |
      cluster_quantile:apiserver_request_latencies:histogram_quantile{job="kubernetes-apiserver",quantile="0.99",subresource!="log",verb!~"^(?:LIST|WATCH|WATCHLIST|PROXY|CONNECT)$"} > 1
    for: 10m
    labels:
      severity: warning
  - alert: {{ cluster }} KubeAPILatencyHigh
    annotations:
      message: {% raw %}The API server has a 99th percentile latency of {{ $value }}
        seconds for {{ $labels.verb }} {{ $labels.resource }}.{% endraw %}

      runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeapilatencyhigh
    expr: |
      cluster_quantile:apiserver_request_latencies:histogram_quantile{job="kubernetes-apiserver",quantile="0.99",subresource!="log",verb!~"^(?:LIST|WATCH|WATCHLIST|PROXY|CONNECT)$"} > 4
    for: 10m
    labels:
      severity: critical
  - alert: {{ cluster }} KubeAPIErrorsHigh
    annotations:
      message: {% raw %}API server is returning errors for {{ $value }}% of requests.{% endraw %}

      runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeapierrorshigh
    expr: |
      sum(rate(apiserver_request_count{job="kubernetes-apiserver",code=~"^(?:5..)$"}[5m])) without(instance, pod)
        /
      sum(rate(apiserver_request_count{job="kubernetes-apiserver"}[5m])) without(instance, pod) * 100 > 10
    for: 10m
    labels:
      severity: critical
  - alert: {{ cluster }} KubeAPIErrorsHigh
    annotations:
      message: {% raw %}API server is returning errors for {{ $value }}% of requests.{% endraw %}

      runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeapierrorshigh
    expr: |
      sum(rate(apiserver_request_count{job="kubernetes-apiserver",code=~"^(?:5..)$"}[5m])) without(instance, pod)
        /
      sum(rate(apiserver_request_count{job="kubernetes-apiserver"}[5m])) without(instance, pod) * 100 > 5
    for: 10m
    labels:
      severity: warning
  - alert: {{ cluster }} KubeClientCertificateExpiration
    annotations:
      message: Kubernetes API certificate is expiring in less than 7 days.
      runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeclientcertificateexpiration
    expr: |
      histogram_quantile(0.01, sum by (job, le) (rate(apiserver_client_certificate_expiration_seconds_bucket{job="kubernetes-apiserver"}[5m]))) < 604800
    labels:
      severity: warning
  - alert: {{ cluster }} KubeClientCertificateExpiration
    annotations:
      message: Kubernetes API certificate is expiring in less than 24 hours.
      runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeclientcertificateexpiration
    expr: |
      histogram_quantile(0.01, sum by (job, le) (rate(apiserver_client_certificate_expiration_seconds_bucket{job="kubernetes-apiserver"}[5m]))) < 86400
    labels:
      severity: critical
- name: alertmanager.rules
  rules:
  - alert: {{ cluster }} AlertmanagerConfigInconsistent
    annotations:
      message: {% raw %}The configuration of the instances of the Alertmanager cluster {{$labels.service}} are out of sync.{% endraw %}

    expr: |
      {% raw %}count_values("config_hash", alertmanager_config_hash{job="{{ $alertmanagerJob }}"}) BY (service) / ON(service) GROUP_LEFT() label_replace(prometheus_operator_alertmanager_spec_replicas{job="{{ $operatorJob }}"}, "service", "alertmanager-$1", "alertmanager", "(.*)") != 1{% endraw %}

    for: 5m
    labels:
      severity: critical
  - alert: {{ cluster }} AlertmanagerFailedReload
    annotations:
      message: {% raw %}Reloading Alertmanager's configuration has failed for {{ $labels.kubernetes_namespace
        }}/{{ $labels.pod}}.{% endraw %}

    expr: |
      {% raw %}alertmanager_config_last_reload_successful{job="{{ $alertmanagerJob }}"} == 0{% endraw %}

    for: 10m
    labels:
      severity: warning
- name: general.rules
  rules:
  - alert: {{ cluster }} TargetDown
    annotations:
      message: {% raw %}'{{ $value }}% of the {{ $labels.job }} targets are down.'{% endraw %}

    expr: 100 * (count(up == 0) BY (job) / count(up) BY (job)) > 10
    for: 10m
    labels:
      severity: warning
  - alert: {{ cluster }} DeadMansSwitch
    annotations:
      message: This is a DeadMansSwitch meant to ensure that the entire alerting pipeline
        is functional.
    expr: vector(1)
    labels:
      severity: none
- name: kube-prometheus-node-alerting.rules
  rules:
  - alert: {{ cluster }} NodeDiskRunningFull
    annotations:
      message: {% raw %}Device {{ $labels.device }} of node-exporter {{ $labels.kubernetes_namespace
        }}/{{ $labels.pod }} will be full within the next 24 hours.{% endraw %}

    expr: |
      (node:node_filesystem_usage: > 0.85) and (predict_linear(node:node_filesystem_avail:[6h], 3600 * 24) < 0)
    for: 30m
    labels:
      severity: warning
  - alert: {{ cluster }} NodeDiskRunningFull
    annotations:
      message: {% raw %}Device {{ $labels.device }} of node-exporter {{ $labels.kubernetes_namespace
        }}/{{ $labels.pod }} will be full within the next 2 hours.{% endraw %}

    expr: |
      (node:node_filesystem_usage: > 0.85) and (predict_linear(node:node_filesystem_avail:[30m], 3600 * 2) < 0)
    for: 10m
    labels:
      severity: critical
- name: prometheus.rules
  rules:
  - alert: {{ cluster }} PrometheusConfigReloadFailed
    annotations:
      description: {% raw %}Reloading Prometheus' configuration has failed for {{$labels.kubernetes_namespace}}/{{$labels.pod}}
      summary: Reloading Prometheus' configuration failed{% endraw %}

    expr: |
      {% raw %}prometheus_config_last_reload_successful{job="{{ $prometheusJob }}"} == 0{% endraw %}

    for: 10m
    labels:
      severity: warning
  - alert: {{ cluster }} PrometheusNotificationQueueRunningFull
    annotations:
      description: {% raw %}Prometheus' alert notification queue is running full for {{$labels.kubernetes_namespace}}/{{
        $labels.pod}}{% endraw %}

      summary: Prometheus' alert notification queue is running full
    expr: |
      {% raw %}predict_linear(prometheus_notifications_queue_length{job="{{ $prometheusJob }}"}[5m], 60 * 30) > prometheus_notifications_queue_capacity{job="{{ $prometheusJob }}"}{% endraw %}

    for: 10m
    labels:
      severity: warning
  - alert: {{ cluster }} PrometheusErrorSendingAlerts
    annotations:
      description: {% raw %}Errors while sending alerts from Prometheus {{$labels.kubernetes_namespace}}/{{
        $labels.pod}} to Alertmanager {{$labels.Alertmanager}}{% endraw %}

      summary: Errors while sending alert from Prometheus
    expr: |
      {% raw %}rate(prometheus_notifications_errors_total{job="{{ $prometheusJob }}"}[5m]) / rate(prometheus_notifications_sent_total{job="{{ $prometheusJob }}"}[5m]) > 0.01{% endraw %}

    for: 10m
    labels:
      severity: warning
  - alert: {{ cluster }} PrometheusErrorSendingAlerts
    annotations:
      description: {% raw %}Errors while sending alerts from Prometheus {{$labels.kubernetes_namespace}}/{{
        $labels.pod}} to Alertmanager {{$labels.Alertmanager}}{% endraw %}

      summary: Errors while sending alerts from Prometheus
    expr: |
      {% raw %}rate(prometheus_notifications_errors_total{job="{{ $prometheusJob }}"}[5m]) / rate(prometheus_notifications_sent_total{job="{{ $prometheusJob }}"}[5m]) > 0.03{% endraw %}

    for: 10m
    labels:
      severity: critical
  - alert: {{ cluster }} PrometheusNotConnectedToAlertmanagers
    annotations:
      description: {% raw %}Prometheus {{ $labels.kubernetes_namespace }}/{{ $labels.pod}}
        is not connected to any Alertmanagers{% endraw %}

      summary: Prometheus is not connected to any Alertmanagers
    expr: |
      {% raw %}prometheus_notifications_alertmanagers_discovered{job="{{ $prometheusJob }}"} < 1{% endraw %}

    for: 10m
    labels:
      severity: warning
  - alert: {{ cluster }} PrometheusTSDBReloadsFailing
    annotations:
      description: {% raw %}'{{$labels.job}} at {{$labels.instance}} had {{$value
        | humanize}} reload failures over the last four hours.'{% endraw %}

      summary: Prometheus has issues reloading data blocks from disk
    expr: |
      {% raw %}increase(prometheus_tsdb_reloads_failures_total{job="{{ $prometheusJob }}"}[2h]) > 0{% endraw %}

    for: 12h
    labels:
      severity: warning
  - alert: {{ cluster }} PrometheusTSDBCompactionsFailing
    annotations:
      description: {% raw %}'{{$labels.job}} at {{$labels.instance}} had {{$value
        | humanize}} compaction failures over the last four hours.'{% endraw %}

      summary: Prometheus has issues compacting sample blocks
    expr: |
      {% raw %}increase(prometheus_tsdb_compactions_failed_total{job="{{ $prometheusJob }}"}[2h]) > 0{% endraw %}

    for: 12h
    labels:
      severity: warning
  - alert: {{ cluster }} PrometheusTSDBWALCorruptions
    annotations:
      description: {% raw %}'{{$labels.job}} at {{$labels.instance}} has a corrupted
        write-ahead log (WAL).'{% endraw %}

      summary: Prometheus write-ahead log is corrupted
    expr: |
      {% raw %}tsdb_wal_corruptions_total{job="{{ $prometheusJob }}"} > 0{% endraw %}

    for: 4h
    labels:
      severity: warning
  - alert: {{ cluster }} PrometheusNotIngestingSamples
    annotations:
      description: {% raw %}Prometheus {{ $labels.kubernetes_namespace }}/{{ $labels.pod}}
        isn't ingesting samples.{% endraw %}

      summary: Prometheus isn't ingesting samples
    expr: |
      {% raw %}rate(prometheus_tsdb_head_samples_appended_total{job="{{ $prometheusJob }}"}[5m]) <= 0{% endraw %}

    for: 10m
    labels:
      severity: warning
  - alert: {{ cluster }} PrometheusTargetScrapesDuplicate
    annotations:
      description: {% raw %}'{{$labels.kubernetes_namespace}}/{{$labels.pod}} has many samples
        rejected due to duplicate timestamps but different values'{% endraw %}

      summary: Prometheus has many samples rejected
    expr: |
      {% raw %}increase(prometheus_target_scrapes_sample_duplicate_timestamp_total{job="{{ $prometheusJob }}"}[5m]) > 0{% endraw %}

    for: 10m
    labels:
      severity: warning
